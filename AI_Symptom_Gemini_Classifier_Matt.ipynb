{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio langchain-google-genai langchain tensorflow pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize Gemini model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    model=GEMINI_MODEL,\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential_4, built=True>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Load trained CNN model\n",
    "cnn_model = load_model(\"saved_models/dementia_cnn_sequential_4_model_V2.keras\")\n",
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Class label map\n",
    "# label_map = {\n",
    "#     0: \"Non-dementia\",\n",
    "#     1: \"Very mild dementia\",\n",
    "#     2: \"Mild dementia\",\n",
    "#     3: \"Moderate dementia\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 7. Function: Classify MRI image\n",
    "# def predict_from_mri(image):\n",
    "#     image = image.resize((224, 224)).convert(\"RGB\")\n",
    "#     array = img_to_array(image) / 255.0\n",
    "#     array = np.expand_dims(array, axis=0)\n",
    "#     preds = cnn_model.predict(array)\n",
    "#     label = label_map[np.argmax(preds)]\n",
    "#     return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_mri(img):\n",
    "    # resize and normalize the image\n",
    "    img = img.convert(\"L\")  # Convert to grayscale\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.repeat(img_array, 3, axis=-1)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    # make prediction\n",
    "    prediction = cnn_model.predict(img_array)\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_label = class_labels[predicted_index]\n",
    "    confidence = float(np.max(prediction))\n",
    "\n",
    "    return f\"{predicted_label} ({confidence*100:.2f}% confidence) Soft Max Class Prediction: {prediction}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Function: Use Gemini to generate natural language explanation\n",
    "def generate_gemini_summary(input_text):\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a dementia diagnostic assistant.\n",
    "\n",
    "Interpret the following patient data or classification and explain what it means in simple, compassionate terms for a family or clinical audience:\n",
    "\n",
    "\"{input_text}\"\n",
    "\n",
    "Do not diagnose or suggest treatment. Just explain what it may indicate about dementia stages.\n",
    "\"\"\")\n",
    "    final_prompt = prompt.format(input_text=input_text)\n",
    "    response = llm.invoke(final_prompt)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict_from_mri,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Dementia MRI Classification\",\n",
    "    description=\"Upload an MRI brain scan to classify into Mild, Moderate, Very Mild, or Non-Demented.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "interface.launch(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 9. Combined chatbot function\n",
    "# def multimodal_chatbot(mri_image, symptom_text):\n",
    "#     responses = []\n",
    "\n",
    "#     if mri_image:\n",
    "#         diagnosis = predict_from_mri(mri_image)\n",
    "#         responses.append(f\"**MRI Image Classification:** {diagnosis}\")\n",
    "#         explanation = generate_gemini_summary(f\"MRI indicates: {diagnosis}\")\n",
    "#         responses.append(f\"**Gemini Summary for MRI:**\\n{explanation}\")\n",
    "\n",
    "#     if symptom_text:\n",
    "#         explanation = generate_gemini_summary(f\"Symptoms: {symptom_text}\")\n",
    "#         responses.append(f\"**Gemini Summary for Symptoms:**\\n{explanation}\")\n",
    "\n",
    "#     if not responses:\n",
    "#         return \"Please upload an MRI image or enter symptom information.\"\n",
    "\n",
    "#     return \"\\n\\n\".join(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10. Gradio UI\n",
    "# gr.Interface(\n",
    "#     fn=multimodal_chatbot,\n",
    "#     inputs=[\n",
    "#         gr.Image(type=\"pil\", label=\"Upload MRI Image\"),\n",
    "#         gr.Textbox(lines=4, placeholder=\"Describe symptoms here...\", label=\"Symptom Description\")\n",
    "#     ],\n",
    "#     outputs=\"markdown\",\n",
    "#     title=\"Dementia MRI & Symptom Assistant (Powered by Gemini)\",\n",
    "#     description=\"Upload an MRI or enter symptoms. The assistant will classify dementia and explain the findings using Google's Gemini 2.0 model.\"\n",
    "# ).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model on just one image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Predicted label: ModerateDemented\n",
      "Confidence: 0.27\n",
      "Class probabilities: [[0.24534394 0.22322693 0.26568407 0.26574507]]\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"saved_models/dementia_cnn_sequential_4_model_V2.keras\")\n",
    "\n",
    "def predict_single_image(image_path):\n",
    "    # Load image and convert to grayscale (your MRI format)\n",
    "    img = image.load_img(image_path, color_mode='grayscale', target_size=(224, 224))\n",
    "\n",
    "    # Convert to array (shape: 224x224x1)\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    # Expand grayscale to 3 channels (shape: 224x224x3)\n",
    "    img_array = np.repeat(img_array, 3, axis=-1)\n",
    "\n",
    "    # Add batch dimension (shape: 1x224x224x3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Normalize like ImageDataGenerator(rescale=1./255)\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    confidence = float(np.max(prediction))\n",
    "\n",
    "    predicted_label = class_labels[predicted_index]\n",
    "    return predicted_label, confidence, prediction\n",
    "\n",
    "# Example usage\n",
    "image_path = 'saved_models/moderateDem33.jpg'  # Change this to your image file path\n",
    "label, conf, full_probs = predict_single_image(image_path)\n",
    "\n",
    "print(f\"Predicted label: {label}\")\n",
    "print(f\"Confidence: {conf:.2f}\")\n",
    "print(f\"Class probabilities: {full_probs}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
