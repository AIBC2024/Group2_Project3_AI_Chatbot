{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio langchain-google-genai langchain tensorflow pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize Gemini model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    model=GEMINI_MODEL,\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load trained CNN model\n",
    "cnn_model = load_model(\"saved_models/dementia_cnn_sequential_4_model_V2.keras\")\n",
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6. Class label map\n",
    "# label_map = {\n",
    "#     0: \"Non-dementia\",\n",
    "#     1: \"Very mild dementia\",\n",
    "#     2: \"Mild dementia\",\n",
    "#     3: \"Moderate dementia\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 7. Function: Classify MRI image\n",
    "# def predict_from_mri(image):\n",
    "#     image = image.resize((224, 224)).convert(\"RGB\")\n",
    "#     array = img_to_array(image) / 255.0\n",
    "#     array = np.expand_dims(array, axis=0)\n",
    "#     preds = cnn_model.predict(array)\n",
    "#     label = label_map[np.argmax(preds)]\n",
    "#     return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_mri(image):\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to grayscale\n",
    "    image = image.convert(\"L\")\n",
    "\n",
    "    # Resize\n",
    "    image = image.resize((224, 224))\n",
    "\n",
    "    # Convert to array\n",
    "    img_array = img_to_array(image)  # shape: (224, 224, 1)\n",
    "\n",
    "    # Repeat grayscale to 3 channels\n",
    "    img_array = np.repeat(img_array, 3, axis=-1)\n",
    "\n",
    "    # Normalize\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    # Add batch dimension\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    preds = cnn_model.predict(img_array)\n",
    "    label = label_map[np.argmax(preds)]\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Function: Use Gemini to generate natural language explanation\n",
    "def generate_gemini_summary(input_text):\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a dementia diagnostic assistant.\n",
    "\n",
    "Interpret the following patient data or classification and explain what it means in simple, compassionate terms for a family or clinical audience:\n",
    "\n",
    "\"{input_text}\"\n",
    "\n",
    "Do not diagnose or suggest treatment. Just explain what it may indicate about dementia stages.\n",
    "\"\"\")\n",
    "    final_prompt = prompt.format(input_text=input_text)\n",
    "    response = llm.invoke(final_prompt)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict_from_mri,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Dementia MRI Classification\",\n",
    "    description=\"Upload an MRI brain scan to classify into Mild, Moderate, Very Mild, or Non-Demented.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "interface.launch(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 9. Combined chatbot function\n",
    "# def multimodal_chatbot(mri_image, symptom_text):\n",
    "#     responses = []\n",
    "\n",
    "#     if mri_image:\n",
    "#         diagnosis = predict_from_mri(mri_image)\n",
    "#         responses.append(f\"**MRI Image Classification:** {diagnosis}\")\n",
    "#         explanation = generate_gemini_summary(f\"MRI indicates: {diagnosis}\")\n",
    "#         responses.append(f\"**Gemini Summary for MRI:**\\n{explanation}\")\n",
    "\n",
    "#     if symptom_text:\n",
    "#         explanation = generate_gemini_summary(f\"Symptoms: {symptom_text}\")\n",
    "#         responses.append(f\"**Gemini Summary for Symptoms:**\\n{explanation}\")\n",
    "\n",
    "#     if not responses:\n",
    "#         return \"Please upload an MRI image or enter symptom information.\"\n",
    "\n",
    "#     return \"\\n\\n\".join(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10. Gradio UI\n",
    "# gr.Interface(\n",
    "#     fn=multimodal_chatbot,\n",
    "#     inputs=[\n",
    "#         gr.Image(type=\"pil\", label=\"Upload MRI Image\"),\n",
    "#         gr.Textbox(lines=4, placeholder=\"Describe symptoms here...\", label=\"Symptom Description\")\n",
    "#     ],\n",
    "#     outputs=\"markdown\",\n",
    "#     title=\"Dementia MRI & Symptom Assistant (Powered by Gemini)\",\n",
    "#     description=\"Upload an MRI or enter symptoms. The assistant will classify dementia and explain the findings using Google's Gemini 2.0 model.\"\n",
    "# ).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model on just one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"saved_models/dementia_cnn_sequential_4_model_V2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(image_path):\n",
    "    # Load grayscale image\n",
    "    img = load_img(image_path, color_mode='grayscale', target_size=(224, 224))\n",
    "\n",
    "    # Convert to array and repeat channels\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.repeat(img_array, 3, axis=-1)\n",
    "\n",
    "    # Normalize\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    preds = cnn_model.predict(img_array)\n",
    "    predicted_index = np.argmax(preds)\n",
    "    confidence = float(np.max(preds))\n",
    "\n",
    "    label = class_labels[predicted_index]\n",
    "\n",
    "    print(f\"Predicted class: {label}\")\n",
    "    print(f\"Confidence score: {confidence:.2f} ({confidence*100:.2f}%)\")\n",
    "    print(\"Raw softmax output:\", preds)\n",
    "\n",
    "    return label, confidence, preds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_prediction_confidence(preds, class_labels):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(class_labels, preds[0])\n",
    "    plt.title(\"Model Confidence per Class\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(\"Dementia Class\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'saved_models/nonDem1311.jpg'  # Change this to your image file path\n",
    "\n",
    "# Example usage\n",
    "label, confidence, preds = predict_single_image(image_path)\n",
    "plot_prediction_confidence(preds, class_labels)\n",
    "\n",
    "# print(f\"Predicted label: {label}\")\n",
    "# print(f\"Confidence: {conf:.2f}\")\n",
    "# print(f\"Class probabilities: {full_probs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
