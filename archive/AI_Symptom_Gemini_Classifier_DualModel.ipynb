{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad27180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Dementia Classifier with MRI Processing and Gemini Integration\n",
    "# Improved version with robust image handling and diagnostics\n",
    "\n",
    "# Core imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Image processing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure, measure, filters\n",
    "\n",
    "\n",
    "# TensorFlow model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce TensorFlow warnings\n",
    "\n",
    "# LLM: Gemini via Langchain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# UI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00257e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "GEMINI_MODEL = \"gemini-2.0-flash\"  # Using latest Gemini model\n",
    "\n",
    "# Initialize Gemini model with low temperature for more predictable outputs\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    model=GEMINI_MODEL,\n",
    "    temperature=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2de6ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=saved_models/dementia_cnn_sequential_4_history_V2.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the CNN model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models/dementia_cnn_sequential_4_history_V2.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m load_model(model_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print model summary and input shape for debugging\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN model loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcnn_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.12/site-packages/keras/src/saving/saving_api.py:200\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: filepath=saved_models/dementia_cnn_sequential_4_history_V2.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "# Load the CNN model\n",
    "model_path = \"saved_models/dementia_cnn_sequential_4_history_V2.keras\"\n",
    "cnn_model = load_model(model_path)\n",
    "\n",
    "# Print model summary and input shape for debugging\n",
    "print(f\"CNN model loaded: {cnn_model.name}\")\n",
    "print(f\"Model input shape: {cnn_model.input_shape}\")\n",
    "print(f\"Model output shape: {cnn_model.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b5e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model expects images of size 240x240 with 3 channels\n"
     ]
    }
   ],
   "source": [
    "# Extract expected input dimensions from the model\n",
    "model_height, model_width = cnn_model.input_shape[1:3]\n",
    "model_channels = cnn_model.input_shape[3]\n",
    "print(f\"Model expects images of size {model_height}x{model_width} with {model_channels} channels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a16fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class label mapping - IMPORTANT: Must match your model's training labels\n",
    "label_map = ['NonDemented', 'VeryMildDemented', 'MildDemented', 'ModerateDemented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d479788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the image with predicted class for validation\n",
    "def display_processed_image(original_image, processed_array, prediction, confidence):\n",
    "    \"\"\"Display the original and processed images side by side with prediction\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Original image\n",
    "    ax1.imshow(original_image)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Processed image - handle both RGB and grayscale\n",
    "    if model_channels == 1:\n",
    "        ax2.imshow(processed_array[0, :, :, 0], cmap='gray')\n",
    "    else:\n",
    "        ax2.imshow(processed_array[0])\n",
    "    ax2.set_title(f\"Processed: {prediction} ({confidence:.2f})\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f0e3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved prediction function with robust image handling\n",
    "def predict_from_mri(image, verbose=True):\n",
    "    \"\"\"Process MRI image and predict dementia class with confidence scores\"\"\"\n",
    "    original_image = image.copy()  # Keep original for display\n",
    "    \n",
    "    # Step 1: Convert to the right color mode (RGB or grayscale)\n",
    "    if model_channels == 1 and image.mode != \"L\":\n",
    "        image = image.convert(\"L\")  # Convert to grayscale\n",
    "        if verbose:\n",
    "            print(\"Converting to grayscale for single-channel model input\")\n",
    "    elif model_channels == 3 and image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")  # Convert to RGB\n",
    "        if verbose:\n",
    "            print(\"Converting to RGB for three-channel model input\")\n",
    "    \n",
    "    # Step 2: Resize image to match model input dimensions\n",
    "    image = image.resize((model_width, model_height))\n",
    "    if verbose:\n",
    "        print(f\"Resized image to {model_width}x{model_height}\")\n",
    "    \n",
    "    # Step 3: Convert to numpy array\n",
    "    img_array = img_to_array(image)\n",
    "    if verbose:\n",
    "        print(f\"Image array shape after conversion: {img_array.shape}\")\n",
    "    \n",
    "    # Step 4: Normalize pixel values to [0, 1]\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    # Step 5: Add batch dimension\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    if verbose:\n",
    "        print(f\"Final input shape for model: {img_array.shape}\")\n",
    "    \n",
    "    # Step 6: Make prediction\n",
    "    preds = cnn_model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Step 7: Get predicted class and confidence\n",
    "    predicted_class = np.argmax(preds)\n",
    "    confidence = float(preds[0][predicted_class])\n",
    "    label = label_map[predicted_class]\n",
    "    \n",
    "    # Step 8: Print prediction details\n",
    "    if verbose:\n",
    "        print(f\"Model prediction: {label} ({confidence:.2f} confidence)\")\n",
    "        print(\"Class probabilities:\")\n",
    "        for i, prob in enumerate(preds[0]):\n",
    "            print(f\"  {label_map[i]}: {prob:.4f}\")\n",
    "    \n",
    "    # Optionally display the processed image\n",
    "    if verbose:\n",
    "        fig = display_processed_image(original_image, img_array, label, confidence)\n",
    "        plt.show()\n",
    "    \n",
    "    return label, confidence, preds[0], img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74728daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate model on test images\n",
    "def validate_model(test_image_path):\n",
    "    \"\"\"Test model on a known image and display results\"\"\"\n",
    "    print(f\"Validating model with test image: {test_image_path}\")\n",
    "    test_image = Image.open(test_image_path)\n",
    "    label, confidence, probs, processed_img = predict_from_mri(test_image)\n",
    "    # Display image with prediction\n",
    "    return label, confidence, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11576a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use Gemini to generate natural language explanation\n",
    "def generate_gemini_summary(input_text):\n",
    "    \"\"\"Use Gemini to explain technical findings in patient-friendly language\"\"\"\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a dementia diagnostic assistant providing information to medical professionals.\n",
    "\n",
    "Interpret the following patient data or classification and explain what it means in simple, compassionate terms suitable for a clinical audience:\n",
    "\n",
    "\"{input_text}\"\n",
    "\n",
    "                                          Focus on:\n",
    "1. Explaining what this classification typically indicates about brain structure and function\n",
    "2. Common cognitive or behavioral symptoms associated with this stage\n",
    "3. Important considerations for the physician to discuss with the patient/family\n",
    "\n",
    "Do not diagnose or suggest specific treatment plans. Just explain what the MRI findings and symptoms may indicate about dementia stages. Be precise but compassionate.\n",
    "\"\"\")\n",
    "    final_prompt = prompt.format(input_text=input_text)\n",
    "    response = llm.invoke(final_prompt)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b7c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_ventricles(image):\n",
    "    \"\"\"Analyze ventricle size to help correct misclassifications\"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if image.mode != \"L\":\n",
    "        image = image.convert(\"L\")\n",
    "    \n",
    "    # Resize for consistency\n",
    "    image = image.resize((240, 240))\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Normalize\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    # Apply CLAHE for better ventricle visibility\n",
    "    img_eq = exposure.equalize_adapthist(img_array, clip_limit=0.03)\n",
    "    \n",
    "    # Create a central region mask where ventricles are typically located\n",
    "    h, w = img_array.shape\n",
    "    center_y, center_x = h // 2, w // 2\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    \n",
    "    # Create masks for ventricle region (typically central)\n",
    "    ventricle_region = (X - center_x)**2 + (Y - center_y)**2 <= (min(h,w)//4)**2\n",
    "    \n",
    "    # Apply threshold to find ventricles (dark regions)\n",
    "    thresh_val = filters.threshold_otsu(img_eq * ventricle_region)\n",
    "    ventricles = (img_eq < thresh_val * 0.8) & ventricle_region\n",
    "    \n",
    "    # Measure ventricle properties\n",
    "    ventricle_size = np.sum(ventricles) / np.sum(ventricle_region)\n",
    "    \n",
    "    # Visualize for debugging\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax1.imshow(img_array, cmap='gray')\n",
    "    ax1.set_title(\"Original MRI\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(img_eq, cmap='gray')\n",
    "    ax2.set_title(\"Enhanced MRI\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3.imshow(img_array, cmap='gray')\n",
    "    ax3.imshow(ventricles, cmap='hot', alpha=0.5)\n",
    "    ax3.set_title(f\"Ventricles (Size: {ventricle_size:.4f})\")\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return ventricle_size, fig\n",
    "\n",
    "def correct_misclassification(original_prediction, ventricle_size, all_probs):\n",
    "    \"\"\"Apply rules to correct common misclassifications based on ventricle analysis\"\"\"\n",
    "    label, confidence = original_prediction\n",
    "    \n",
    "    # Create a dictionary for easier referencing\n",
    "    class_probs = {label_map[i]: prob for i, prob in enumerate(all_probs)}\n",
    "    \n",
    "    # Rule 1: Large ventricles typically indicate moderate or severe dementia\n",
    "    if ventricle_size > 0.12:  # Threshold determined empirically\n",
    "        if label == \"VeryMildDemented\" or label == \"MildDemented\":\n",
    "            # Check if there's reasonable probability for moderate\n",
    "            if class_probs[\"ModerateDemented\"] > 0.1:  # Even a small probability\n",
    "                return \"ModerateDemented\", class_probs[\"ModerateDemented\"]\n",
    "            # Upgrade at least to mild if predicted as very mild\n",
    "            elif label == \"VeryMildDemented\" and class_probs[\"MildDemented\"] > 0.1:\n",
    "                return \"MildDemented\", class_probs[\"MildDemented\"]\n",
    "    \n",
    "    # Rule 2: If moderate is the second highest prediction with close probability\n",
    "    sorted_probs = sorted(class_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    if sorted_probs[0][0] != \"ModerateDemented\" and sorted_probs[1][0] == \"ModerateDemented\":\n",
    "        if sorted_probs[1][1] > 0.7 * sorted_probs[0][1] and ventricle_size > 0.1:\n",
    "            return \"ModerateDemented\", sorted_probs[1][1]\n",
    "    \n",
    "    # No correction needed\n",
    "    return label, confidence\n",
    "\n",
    "# Modify your existing predict_from_mri function to include this correction\n",
    "def enhanced_predict_from_mri(image):\n",
    "    \"\"\"Enhanced prediction with ventricle analysis to correct misclassifications\"\"\"\n",
    "    # Step 1: Get original model prediction\n",
    "    label, confidence, all_probs, processed_img = predict_from_mri(image, verbose=False)\n",
    "    \n",
    "    # Step 2: Analyze ventricles\n",
    "    ventricle_size, ventricle_fig = analyze_ventricles(image)\n",
    "    print(f\"Ventricle analysis complete - size: {ventricle_size:.4f}\")\n",
    "    \n",
    "    # Step 3: Apply correction rules\n",
    "    corrected_label, corrected_confidence = correct_misclassification(\n",
    "        (label, confidence), ventricle_size, all_probs)\n",
    "    \n",
    "    # Step 4: Log the correction if any\n",
    "    if label != corrected_label:\n",
    "        print(f\"⚠️ Prediction corrected: {label} → {corrected_label}\")\n",
    "        print(f\"Original confidence: {confidence:.4f}, Corrected confidence: {corrected_confidence:.4f}\")\n",
    "    else:\n",
    "        print(f\"✓ Original prediction maintained: {label} ({confidence:.4f})\")\n",
    "    \n",
    "    # Return both original and corrected predictions\n",
    "    return {\n",
    "        \"original\": {\"label\": label, \"confidence\": confidence},\n",
    "        \"corrected\": {\"label\": corrected_label, \"confidence\": corrected_confidence},\n",
    "        \"ventricle_size\": ventricle_size,\n",
    "        \"probabilities\": all_probs,\n",
    "        \"visualization\": ventricle_fig\n",
    "    }\n",
    "\n",
    "# Update your multimodal_chatbot function to use the enhanced prediction\n",
    "def improved_multimodal_chatbot(mri_image, symptom_text):\n",
    "    \"\"\"Improved chatbot with ventricle analysis to fix misclassifications\"\"\"\n",
    "    responses = []\n",
    "    \n",
    "    mri_text = \"\"\n",
    "    symptom_summary = \"\"\n",
    "    \n",
    "    if mri_image is not None:\n",
    "        try:\n",
    "            # Use enhanced prediction with ventricle analysis\n",
    "            result = enhanced_predict_from_mri(mri_image)\n",
    "            \n",
    "            # Extract results\n",
    "            original = result[\"original\"]\n",
    "            corrected = result[\"corrected\"]\n",
    "            ventricle_size = result[\"ventricle_size\"]\n",
    "            all_probs = result[\"probabilities\"]\n",
    "            \n",
    "            # Format probabilities for all classes\n",
    "            class_probs = [f\"{label_map[i]}: {prob:.4f}\" for i, prob in enumerate(all_probs)]\n",
    "            prob_text = \", \".join(class_probs)\n",
    "            \n",
    "            # Add results to responses\n",
    "            responses.append(f\"**MRI Classification:** {corrected['label']} (Confidence: {corrected['confidence']:.4f})\")\n",
    "            \n",
    "            if original['label'] != corrected['label']:\n",
    "                responses.append(f\"*Note: Original model prediction ({original['label']}) was corrected based on ventricle analysis (size: {ventricle_size:.4f})*\")\n",
    "            \n",
    "            responses.append(f\"**All Probabilities:** {prob_text}\")\n",
    "            \n",
    "            # Store MRI analysis for combined reasoning\n",
    "            mri_text = (f\"MRI analysis indicates a classification of **{corrected['label']}** with \"\n",
    "                         f\"confidence of {corrected['confidence']:.4f}. Ventricle analysis shows \"\n",
    "                         f\"a ventricle size of {ventricle_size:.4f}, which is \"\n",
    "                         f\"{'enlarged' if ventricle_size > 0.12 else 'within normal range'}.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing MRI image: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            responses.append(f\"**Error:** {error_msg}\")\n",
    "    \n",
    "    # Rest of your function remains the same...\n",
    "    # Process symptoms, generate Gemini summary, etc.\n",
    "    \n",
    "    return \"\\n\\n\".join(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2afaf965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a diagnostic tool to validate the model on test images\n",
    "def diagnostic_tool():\n",
    "    \"\"\"Run a series of diagnostic tests on the model with sample images\"\"\"\n",
    "    print(\"Running model diagnostics...\")\n",
    "    \n",
    "    # Check if test directory exists\n",
    "    test_dir = \"test_images\"\n",
    "    if not os.path.exists(test_dir):\n",
    "        print(f\"Test directory {test_dir} not found. Please create it and add sample MRI images.\")\n",
    "        return\n",
    "    \n",
    "    # Get list of test images\n",
    "    test_images = [f for f in os.listdir(test_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not test_images:\n",
    "        print(\"No test images found. Add some sample MRIs to the test_images directory.\")\n",
    "        return\n",
    "    \n",
    "    # Test each image\n",
    "    results = []\n",
    "    for img_file in test_images:\n",
    "        img_path = os.path.join(test_dir, img_file)\n",
    "        print(f\"\\nTesting image: {img_file}\")\n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "            label, confidence, probs, _ = predict_from_mri(image)\n",
    "            results.append({\n",
    "                'image': img_file,\n",
    "                'prediction': label,\n",
    "                'confidence': confidence,\n",
    "                'probabilities': probs\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {str(e)}\")\n",
    "    \n",
    "    # Print summary of results\n",
    "    print(\"\\n=== Diagnostic Results ===\")\n",
    "    for r in results:\n",
    "        print(f\"Image: {r['image']}, Prediction: {r['prediction']}, Confidence: {r['confidence']:.4f}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e1d6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio Interface with improved layout and error handling\n",
    "def create_gradio_interface():\n",
    "    \"\"\"Create and launch Gradio UI for the dementia classifier\"\"\"\n",
    "    \n",
    "    with gr.Blocks(title=\"Enhanced Dementia MRI & Symptom Assistant\") as demo:\n",
    "        gr.Markdown(\"# Dementia MRI & Symptom Assistant (Powered by Gemini)\")\n",
    "        gr.Markdown(\"Upload an MRI scan and/or enter symptoms to receive AI-assisted analysis.\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                # Input components\n",
    "                image_input = gr.Image(\n",
    "                    type=\"pil\", \n",
    "                    label=\"Upload MRI Image\",\n",
    "                    elem_id=\"mri-upload\"\n",
    "                )\n",
    "                \n",
    "                symptom_input = gr.Textbox(\n",
    "                    lines=4, \n",
    "                    placeholder=\"Describe symptoms, cognitive issues, and relevant patient history...\", \n",
    "                    label=\"Clinical Notes & Symptoms\"\n",
    "                )\n",
    "                \n",
    "                submit_btn = gr.Button(\"Analyze\", variant=\"primary\")\n",
    "                \n",
    "            with gr.Column():\n",
    "                # Output components\n",
    "                output = gr.Markdown(label=\"Analysis Results\")\n",
    "        \n",
    "        # Set up event handler\n",
    "        submit_btn.click(\n",
    "            fn=improved_multimodal_chatbot,\n",
    "            inputs=[image_input, symptom_input],\n",
    "            outputs=output\n",
    "        )\n",
    "        \n",
    "        gr.Markdown(\"### Disclaimer: This tool is for research purposes only and not for clinical use.\")\n",
    "    \n",
    "    # Launch the interface\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90106df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ventricle analysis complete - size: 0.2853\n",
      "✓ Original prediction maintained: MildDemented (1.0000)\n",
      "Ventricle analysis complete - size: 0.3056\n",
      "✓ Original prediction maintained: MildDemented (1.0000)\n",
      "Ventricle analysis complete - size: 0.2493\n",
      "✓ Original prediction maintained: MildDemented (1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Main execution function\n",
    "if __name__ == \"__main__\":\n",
    "    # Option 1: Run diagnostic tests on sample images\n",
    "    # diagnostic_tool()\n",
    "    \n",
    "    # Option 2: Launch the Gradio interface\n",
    "    create_gradio_interface()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
